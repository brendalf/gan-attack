{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/brendalf/Documents/projects/gan-attack/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((32, 32)),\n",
    "    ToTensor() \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = STL10(\n",
    "    root='../data', split='train', download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating dataset with N images per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder = '../data/cifar10_attack_v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(new_folder):\n",
    "    os.mkdir(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, lbl = next(iter(trainset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n class no stl => n class cifar 10\n",
    "\n",
    "map_classes = {\n",
    "    0: 0, # airplane\n",
    "    2: 1, # auto\n",
    "    1: 2, # bird\n",
    "    3: 3, # cat\n",
    "    4: 4, # deer\n",
    "    5: 5, # dog\n",
    "    # 7: 6, # monkey | frog\n",
    "    6: 7, # horse\n",
    "    8: 8, # sheep\n",
    "    9: 9, # truck\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {l:0 for l in np.arange(0, 10)}\n",
    "num = 500\n",
    "\n",
    "for image, label in trainset: \n",
    "    if label in map_classes.keys():\n",
    "        label = map_classes[label]\n",
    "        \n",
    "        label_folder = os.path.join(new_folder, str(label))\n",
    "\n",
    "        if not os.path.exists(label_folder):\n",
    "            os.mkdir(label_folder)\n",
    "        \n",
    "        if labels[label] == num:\n",
    "            continue\n",
    "\n",
    "        torchvision.utils.save_image(image, fp=os.path.join(label_folder, f'{labels[label]}.png'))\n",
    "        labels[label] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting frog from ImageNet to replace monkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_frog = 'n01644373'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "frogs = os.listdir(os.path.join('../data/imagenet/', id_frog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"{new_folder}/6\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for img_frog in np.random.choice(frogs, num, replace=False):\n",
    "    copyfile(f\"../data/imagenet/{id_frog}/{img_frog}\", f\"{new_folder}/6/{i}.jpg\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stealing labels from target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = VGG('VGG19')\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "checkpoint = torch.load('../models/target/cifar10.vgg19.pth')\n",
    "net.load_state_dict(checkpoint['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, '../models/target/cifar10.vgg19.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG('VGG19')\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "checkpoint = torch.load('../models/target/cifar10.vgg19.pth')\n",
    "net.load_state_dict(checkpoint['net'])\n",
    "net = net.to(device)\n",
    "\n",
    "norm = Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "stolen_labels_folder = '../data/cifar10_attack_labeled_vgg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from target.custom import CustomNN\n",
    "\n",
    "net = CustomNN()\n",
    "net = torch.load('../models/target/cifar10.custom.pth')\n",
    "net = net.to(device)\n",
    "\n",
    "norm = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "stolen_labels_folder = '../data/cifar10_attack_labeled_custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder = '../data/cifar10_attack'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose([\n",
    "    Resize((32,32)),\n",
    "    ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(root=new_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(stolen_labels_folder):\n",
    "    os.mkdir(stolen_labels_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/5000 [00:00<04:17, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating labels from target...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:21<00:00, 235.26it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "real_labels = np.array([])\n",
    "pred_labels = np.array([])\n",
    "\n",
    "print('Generating labels from target...')\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    \n",
    "    for images, labels in tqdm(dataloader):\n",
    "        real_labels = np.append(real_labels, labels.numpy())\n",
    "        images = images.to(device)\n",
    "        \n",
    "        # simulando o processamento da api, pois eu n conheco a norm e preciso salvar a imagem original\n",
    "        images_norm = norm(images.view(3, 32, 32)).view(1, 3, 32, 32)\n",
    "        \n",
    "        outputs = net(images_norm)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predicted = predicted.cpu().numpy()\n",
    "\n",
    "        new_idx = len(pred_labels[pred_labels == predicted[0]])\n",
    "        pred_labels = np.append(pred_labels, predicted)\n",
    "\n",
    "\n",
    "        label_folder = os.path.join(stolen_labels_folder, str(predicted[0]))\n",
    "        if not os.path.exists(label_folder):\n",
    "            os.mkdir(label_folder)\n",
    "        \n",
    "        torchvision.utils.save_image(\n",
    "            images,\n",
    "            fp=os.path.join(label_folder, f'{new_idx}.png')    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 500.],\n",
       "       [  1., 500.],\n",
       "       [  2., 500.],\n",
       "       [  3., 500.],\n",
       "       [  4., 500.],\n",
       "       [  5., 500.],\n",
       "       [  6., 500.],\n",
       "       [  7., 500.],\n",
       "       [  8., 500.],\n",
       "       [  9., 500.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(real_labels, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., 581.],\n",
       "       [  1., 489.],\n",
       "       [  2., 566.],\n",
       "       [  3., 538.],\n",
       "       [  4., 599.],\n",
       "       [  5., 390.],\n",
       "       [  6., 387.],\n",
       "       [  7., 473.],\n",
       "       [  8., 530.],\n",
       "       [  9., 447.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unique, counts) = np.unique(pred_labels, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, Resize, Normalize, ToTensor\n",
    "from torchvision.datasets import STL10\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '/home/brendalf/Documents/projects/gan-attack/src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform():\n",
    "    transform = Compose([\n",
    "        Resize((32,32)),\n",
    "        ToTensor()     \n",
    "    ])\n",
    "    \n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Files already downloaded and verified\n"
    }
   ],
   "source": [
    "trainset = STL10(\n",
    "    root='../data', split='train', download=True, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision"
   ]
  },
  {
   "source": [
    "## Generating dataset with 100 images per class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder = '../data/stl10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(new_folder):\n",
    "    os.mkdir(new_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {l:0 for l in np.arange(0, 10)}\n",
    "num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in trainset:\n",
    "    label_folder = os.path.join(new_folder, str(label))\n",
    "\n",
    "    if not os.path.exists(label_folder):\n",
    "        os.mkdir(label_folder)\n",
    "    \n",
    "    if labels[label] == 100:\n",
    "        continue\n",
    "\n",
    "    torchvision.utils.save_image(image, fp=os.path.join(label_folder, f'{labels[label]}.png'))\n",
    "    labels[label] += 1"
   ]
  },
  {
   "source": [
    "## Stealing labels from target"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.target.cifar10 import Cifar10Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('../models/target/cifar10.custom.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(root=new_folder, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "  0%|          | 0/32 [00:00&lt;?, ?it/s]Generating labels from target...\n100%|██████████| 32/32 [00:00&lt;00:00, 157.72it/s]\n"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "  \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "real_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "print('Generating labels from target...')\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    \n",
    "    with open(output_labels, 'w') as output_fd:\n",
    "        for images, labels in tqdm(dataloader):\n",
    "            real_labels.extend(labels.numpy())\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            pred_labels.extend(predicted.cpu().numpy())\n",
    "            \n",
    "            output_fd.writelines(\n",
    "                ['{},{}\\n'.format(img_fn, label) for img_fn, label \n",
    "                    in zip(filenames, predicted)\n",
    "                ]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  0, 100],\n       [  1, 100],\n       [  2, 100],\n       [  3, 100],\n       [  4, 100],\n       [  5, 100],\n       [  6, 100],\n       [  7, 100],\n       [  8, 100],\n       [  9, 100]])"
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "(unique, counts) = np.unique(real_labels, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[  0, 128],\n       [  1,  21],\n       [  2,  67],\n       [  3, 295],\n       [  4,  93],\n       [  5,  86],\n       [  6,   9],\n       [  7,  30],\n       [  8, 245],\n       [  9,  26]])"
     },
     "metadata": {},
     "execution_count": 151
    }
   ],
   "source": [
    "(unique, counts) = np.unique(pred_labels, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}